\section{The Elements of Programming}
\label{Section 1.1}

A powerful programming language is more than just a means for instructing a
computer to perform tasks.  The language also serves as a framework within
which we organize our ideas about processes.  Thus, when we describe a
language, we should pay particular attention to the means that the language
provides for combining simple ideas to form more complex ideas.  Every powerful
language has three mechanisms for accomplishing this:

\begin{itemize}

\item \textbf{primitive expressions},
which represent the simplest entities the language is concerned with,

\item \textbf{means of combination},
by which compound elements are built from simpler ones, and

\item \textbf{means of abstraction},
by which compound elements can be named and manipulated as units.

\end{itemize}

\noindent
In programming, we deal with two kinds of elements: procedures and data. (Later
we will discover that they are really not so distinct.)  Informally, data is
``stuff\( \kern0.1em \)'' that we want to manipulate, and procedures are descriptions of the
rules for manipulating the data.  Thus, any powerful programming language
should be able to describe primitive data and primitive procedures and should
have methods for combining and abstracting procedures and data.

In this chapter we will deal only with simple numerical data so that we can
focus on the rules for building procedures.\footnote{The characterization of
numbers as ``simple data'' is a barefaced bluff.  In fact, the treatment of
numbers is one of the trickiest and most confusing aspects of any programming
language.  Some typical issues involved are these: Some computer systems
distinguish \newterm{integers}, such as 2, from \newterm{real numbers}, such as
2.71.  Is the real number 2.00 different from the integer 2?  Are the
arithmetic operations used for integers the same as the operations used for
real numbers?  Does 6 divided by 2 produce 3, or 3.0?  How large a number can
we represent?  How many decimal places of accuracy can we represent?  Is the
range of integers the same as the range of real numbers?  Above and beyond
these questions, of course, lies a collection of issues concerning roundoff and
truncation errors---the entire science of numerical analysis.  Since our focus
in this book is on large-scale program design rather than on numerical
techniques, we are going to ignore these problems.  The numerical examples in
this chapter will exhibit the usual roundoff behavior that one observes when
using arithmetic operations that preserve a limited number of decimal places of
accuracy in noninteger operations.} In later chapters we will see that these
same rules allow us to build procedures to manipulate compound data as well.



\subsection{Expressions}
\label{Section 1.1.1}

One easy way to get started at programming is to examine some typical
interactions with an interpreter for the Scheme dialect of Lisp.  Imagine that
you are sitting at a computer terminal.  You type an \newterm{expression}, and
the interpreter responds by displaying the result of its \newterm{evaluating}
that expression.

One kind of primitive expression you might type is a number.  (More precisely,
the expression that you type consists of the numerals that represent the number
in base 10.)  If you present Lisp with a number

\begin{scheme}
486
\end{scheme}

\noindent
the interpreter will respond by printing\footnote{Throughout this book, when
we wish to emphasize the distinction between the input typed by the user and
the response printed by the interpreter, we will show the latter in slanted
characters.}

\begin{scheme}
~\textit{486}~
\end{scheme}

\noindent
Expressions representing numbers may be combined with an expression
representing a primitive procedure (such as \code{+} or \code{*}) to form a
compound expression that represents the application of the procedure to those
numbers.  For example:

\begin{scheme}
(+ 137 349)
~\textit{486}~
\end{scheme}

\begin{scheme}
(- 1000 334)
~\textit{666}~
\end{scheme}

\begin{scheme}
(* 5 99)
~\textit{495}~
\end{scheme}

\begin{scheme}
(/ 10 5)
~\textit{2}~
\end{scheme}

\begin{scheme}
(+ 2.7 10)
~\textit{12.7}~
\end{scheme}

\noindent
Expressions such as these, formed by delimiting a list of expressions within
parentheses in order to denote procedure application, are called
\newterm{combinations}.  The leftmost element in the list is called the
\newterm{operator}, and the other elements are called \newterm{operands}.  The
value of a combination is obtained by applying the procedure specified by the
operator to the \newterm{arguments} that are the values of the operands.

The convention of placing the operator to the left of the operands is known as
\newterm{prefix notation}, and it may be somewhat confusing at first because it
departs significantly from the customary mathematical convention.  Prefix
notation has several advantages, however.  One of them is that it can
accommodate procedures that may take an arbitrary number of arguments, as in
the following examples:

\begin{scheme}
(+ 21 35 12 7)
~\textit{75}~
\end{scheme}

\begin{scheme}
(* 25 4 12)
~\textit{1200}~
\end{scheme}

\noindent
No ambiguity can arise, because the operator is always the leftmost element and
the entire combination is delimited by the parentheses.

A second advantage of prefix notation is that it extends in a straightforward
way to allow combinations to be \textit{nested}, that is, to have combinations whose
elements are themselves combinations:

\begin{scheme}
(+ (* 3 5) (- 10 6))
~\textit{19}~
\end{scheme}

\noindent
There is no limit (in principle) to the depth of such nesting and to the
overall complexity of the expressions that the Lisp interpreter can evaluate.
It is we humans who get confused by still relatively simple expressions such as

\begin{scheme}
(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))
\end{scheme}

\noindent
which the interpreter would readily evaluate to be 57.  We can help ourselves
by writing such an expression in the form

\begin{scheme}
(+ (* 3
      (+ (* 2 4)
         (+ 3 5)))
   (+ (- 10 7)
      6))
\end{scheme}

\noindent
following a formatting convention known as \newterm{pretty-printing}, in which
each long combination is written so that the operands are aligned vertically.
The resulting indentations display clearly the structure of the
expression.\footnote{Lisp systems typically provide features to aid the user in
formatting expressions.  Two especially useful features are one that
automatically indents to the proper pretty-print position whenever a new line
is started and one that highlights the matching left parenthesis whenever a
right parenthesis is typed.}

Even with complex expressions, the interpreter always operates in the same
basic cycle: It reads an expression from the terminal, evaluates the
expression, and prints the result.  This mode of operation is often expressed
by saying that the interpreter runs in a \newterm{read-eval-print loop}.
Observe in particular that it is not necessary to explicitly instruct the
interpreter to print the value of the expression.\footnote{Lisp obeys the
convention that every expression has a value. This convention, together with
the old reputation of Lisp as an inefficient language, is the source of the
quip by Alan Perlis (paraphrasing Oscar Wilde) that ``Lisp programmers know the
value of everything but the cost of nothing.''}

\subsection{Naming and the Environment}
\label{Section 1.1.2}

A critical aspect of a programming language is the means it provides for using
names to refer to computational objects.  We say that the name identifies a
\newterm{variable} whose \newterm{value} is the object.

In the Scheme dialect of Lisp, we name things with \code{define}.  Typing

\begin{scheme}
(define size 2)
\end{scheme}

\noindent
causes the interpreter to associate the value 2 with the name
\code{size}.\footnote{In this book, we do not show the interpreter's response
to evaluating definitions, since this is highly implementation-dependent.} Once
the name \code{size} has been associated with the number 2, we can refer to the
value 2 by name:

\begin{scheme}
size
~\textit{2}~
\end{scheme}

\begin{scheme}
(* 5 size)
~\textit{10}~
\end{scheme}

\noindent
Here are further examples of the use of \code{define}:

\begin{scheme}
(define pi 3.14159)
(define radius 10)
(* pi (* radius radius))
~\textit{314.159}~
(define circumference (* 2 pi radius))
circumference
~\textit{62.8318}~
\end{scheme}

\noindent
\code{define} is our language's simplest means of abstraction, for it allows us
to use simple names to refer to the results of compound operations, such as the
\code{circumference} computed above.  In general, computational objects may
have very complex structures, and it would be extremely inconvenient to have to
remember and repeat their details each time we want to use them.  Indeed,
complex programs are constructed by building, step by step, computational
objects of increasing complexity. The interpreter makes this step-by-step
program construction particularly convenient because name-object associations
can be created incrementally in successive interactions.  This feature
encourages the incremental development and testing of programs and is largely
responsible for the fact that a Lisp program usually consists of a large number
of relatively simple procedures.

It should be clear that the possibility of associating values with symbols and
later retrieving them means that the interpreter must maintain some sort of
memory that keeps track of the name-object pairs.  This memory is called the
\newterm{environment} (more precisely the \newterm{global environment}, since
we will see later that a computation may involve a number of different
environments).\footnote{\link{Chapter 3} will show that this notion of
environment is crucial, both for understanding how the interpreter works and
for implementing interpreters.}

\subsection{Evaluating Combinations}
\label{Section 1.1.3}

One of our goals in this chapter is to isolate issues about thinking
procedurally.  As a case in point, let us consider that, in evaluating
combinations, the interpreter is itself following a procedure.

To evaluate a combination, do the following:

\begin{enumerate}

\item
Evaluate the subexpressions of the combination.

\item
Apply the procedure that is the value of the leftmost subexpression (the
operator) to the arguments that are the values of the other subexpressions (the
operands).

\end{enumerate}

\noindent
Even this simple rule illustrates some important points about processes in
general.  First, observe that the first step dictates that in order to
accomplish the evaluation process for a combination we must first perform the
evaluation process on each element of the combination.  Thus, the evaluation
rule is \newterm{recursive} in nature; that is, it includes, as one of its
steps, the need to invoke the rule itself.\footnote{It may seem strange that
the evaluation rule says, as part of the first step, that we should evaluate
the leftmost element of a combination, since at this point that can only be an
operator such as \code{+} or \code{*} representing a built-in primitive
procedure such as addition or multiplication.  We will see later that it is
useful to be able to work with combinations whose operators are themselves
compound expressions.}

Notice how succinctly the idea of recursion can be used to express what, in the
case of a deeply nested combination, would otherwise be viewed as a rather
complicated process.  For example, evaluating

\begin{scheme}
(* (+ 2 (* 4 6))
   (+ 3 5 7))
\end{scheme}

\noindent
requires that the evaluation rule be applied to four different combinations.
We can obtain a picture of this process by representing the combination in the
form of a tree, as shown in \link{Figure 1.1}.  Each combination is represented
by a node with branches corresponding to the operator and the operands of the
combination stemming from it.  The terminal nodes (that is, nodes with no
branches stemming from them) represent either operators or numbers.  Viewing
evaluation in terms of the tree, we can imagine that the values of the operands
percolate upward, starting from the terminal nodes and then combining at higher
and higher levels.  In general, we shall see that recursion is a very powerful
technique for dealing with hierarchical, treelike objects.  In fact, the
``percolate values upward'' form of the evaluation rule is an example of a
general kind of process known as \newterm{tree accumulation}.

\begin{figure}[tb]
\phantomsection\label{Figure 1.1}
\centering
\begin{comment}
\heading{Figure 1.1:} Tree representation, showing the value of each subcombination.

\begin{example}
   390
   /|\____________
  / |             \
 *  26            15
    /|\           /|\
   / | \         // \\
  +  2  24      / | | \
        /|\    +  3 5  7
       / | \
      *  4  6
\end{example}
\end{comment}
\includesvg[width=31mm]{fig/chap1/Fig1.1g.svg}
\begin{quote}
\heading{Figure 1.1:} Tree representation, showing the value of each subcombination.
\end{quote}
\end{figure}

Next, observe that the repeated application of the first step brings us to the
point where we need to evaluate, not combinations, but primitive expressions
such as numerals, built-in operators, or other names.  We take care of the
primitive cases by stipulating that

\begin{itemize}

\item
the values of numerals are the numbers that they name,

\item
the values of built-in operators are the machine instruction sequences that
carry out the corresponding operations, and

\item
the values of other names are the objects associated with those names in the
environment.

\end{itemize}

\noindent
We may regard the second rule as a special case of the third one by stipulating
that symbols such as \code{+} and \code{*} are also included in the global
environment, and are associated with the sequences of machine instructions that
are their ``values.''  The key point to notice is the role of the environment
in determining the meaning of the symbols in expressions.  In an interactive
language such as Lisp, it is meaningless to speak of the value of an expression
such as \code{(+ x 1)} without specifying any information about the environment
that would provide a meaning for the symbol \code{x} (or even for the symbol
\code{+}).  As we shall see in \link{Chapter 3}, the general notion of the
environment as providing a context in which evaluation takes place will play an
important role in our understanding of program execution.

Notice that the evaluation rule given above does not handle definitions.  For
instance, evaluating \code{(define x 3)} does not apply \code{define} to two
arguments, one of which is the value of the symbol \code{x} and the other of
which is 3, since the purpose of the \code{define} is precisely to associate
\code{x} with a value.  (That is, \code{(define x 3)} is not a combination.)

Such exceptions to the general evaluation rule are called \newterm{special
forms}.  \code{define} is the only example of a special form that we have seen
so far, but we will meet others shortly.  Each special form has its own
evaluation rule. The various kinds of expressions (each with its associated
evaluation rule) constitute the syntax of the programming language.  In
comparison with most other programming languages, Lisp has a very simple
syntax; that is, the evaluation rule for expressions can be described by a
simple general rule together with specialized rules for a small number of
special forms.\footnote{Special syntactic forms that are simply convenient
alternative surface structures for things that can be written in more uniform
ways are sometimes called \newterm{syntactic sugar}, to use a phrase coined by
Peter Landin.  In comparison with users of other languages, Lisp programmers,
as a rule, are less concerned with matters of syntax.  (By contrast, examine
any Pascal manual and notice how much of it is devoted to descriptions of
syntax.)  This disdain for syntax is due partly to the flexibility of Lisp,
which makes it easy to change surface syntax, and partly to the observation
that many ``convenient'' syntactic constructs, which make the language less
uniform, end up causing more trouble than they are worth when programs become
large and complex.  In the words of Alan Perlis, ``Syntactic sugar causes
cancer of the semicolon.''}

\subsection{Compound Procedures}
\label{Section 1.1.4}

We have identified in Lisp some of the elements that must appear in any
powerful programming language:

\begin{itemize}

\item
Numbers and arithmetic operations are primitive data and procedures.

\item
Nesting of combinations provides a means of combining operations.

\item
Definitions that associate names with values provide a limited means of
abstraction.

\end{itemize}

\noindent
Now we will learn about \newterm{procedure definitions}, a much more powerful
abstraction technique by which a compound operation can be given a name and
then referred to as a unit.

We begin by examining how to express the idea of ``squaring.''  We might say,
``To square something, multiply it by itself.''  This is expressed in our
language as

\begin{scheme}
(define (square x) (* x x))
\end{scheme}

\noindent
We can understand this in the following way:

\begin{scheme}
(define (square    x)         (*      x         x))
  |        |       |           |      |         |
 To     square  something,  multiply  it  by  itself.
\end{scheme}

\noindent
We have here a \newterm{compound procedure}, which has been given the name
\code{square}.  The procedure represents the operation of multiplying something
by itself.  The thing to be multiplied is given a local name, \code{x}, which
plays the same role that a pronoun plays in natural language.  Evaluating the
definition creates this compound procedure and associates it with the name
\code{square}.\footnote{Observe that there are two different operations being
combined here: we are creating the procedure, and we are giving it the name
\code{square}.  It is possible, indeed important, to be able to separate these
two notions---to create procedures without naming them, and to give names to
procedures that have already been created.  We will see how to do this in
\link{Section 1.3.2}.}

The general form of a procedure definition is

\begin{scheme}
(define (~\( \dark \langle \)~~\var{\dark name}~~\( \dark \kern0.03em\rangle \)~ ~\( \dark \langle \)~~\var{\dark formal parameters}~~\( \dark \kern0.02em\rangle \)~)
  ~\( \dark \langle\kern0.08em \)~~\var{\dark body}~~\( \dark \rangle \)~)
\end{scheme}

\noindent
The \( \langle\hbox{\sl name}\kern0.08em\rangle \) is a symbol to be associated with the procedure definition in
the environment.\footnote{Throughout this book, we will describe the general
syntax of expressions by using italic symbols delimited by angle
brackets---e.g., \( \langle \)\var{name}\( \kern0.08em\rangle \)---to denote the ``slots'' in the expression to be
filled in when such an expression is actually used.} The \( \langle\hbox{\sl formal parameters}\kern0.08em\rangle \) are the names used within the body of the procedure to refer to
the corresponding arguments of the procedure.  The \( \langle\hbox{\sl body}\kern0.08em\rangle \) is an
expression that will yield the value of the procedure application when the
formal parameters are replaced by the actual arguments to which the procedure
is applied.\footnote{More generally, the body of the procedure can be a
sequence of expressions.  In this case, the interpreter evaluates each
expression in the sequence in turn and returns the value of the final
expression as the value of the procedure application.}  The \( \langle \)\var{name}\( \kern0.08em\rangle \) and
the \( \langle \)\var{formal parameters}\( \kern0.08em\rangle \) are grouped within parentheses, just as they
would be in an actual call to the procedure being defined.

Having defined \code{square}, we can now use it:

\begin{scheme}
(square 21)
~\textit{441}~
(square (+ 2 5))
~\textit{49}~
(square (square 3))
~\textit{81}~
\end{scheme}

\noindent
We can also use \code{square} as a building block in defining other procedures.
For example, \( x^2 + y^2 \) can be expressed as

\begin{scheme}
(+ (square x) (square y))
\end{scheme}

\noindent
We can easily define a procedure \code{sum\-/of\-/squares} that, given any two
numbers as arguments, produces the sum of their squares:

\begin{scheme}
(define (sum-of-squares x y)
  (+ (square x) (square y)))
(sum-of-squares 3 4)
~\textit{25}~
\end{scheme}

\noindent
Now we can use \code{sum\-/of\-/squares} as a building block in constructing
further procedures:

\begin{scheme}
(define (f a)
  (sum-of-squares (+ a 1) (* a 2)))
(f 5)
~\textit{136}~
\end{scheme}

\noindent
Compound procedures are used in exactly the same way as primitive procedures.
Indeed, one could not tell by looking at the definition of
\code{sum\-/of\-/squares} given above whether \code{square} was built into the
interpreter, like \code{+} and \code{*}, or defined as a compound procedure.

\subsection{The Substitution Model for Procedure Application}
\label{Section 1.1.5}

To evaluate a combination whose operator names a compound procedure, the
interpreter follows much the same process as for combinations whose operators
name primitive procedures, which we described in \link{Section 1.1.3}.  That is,
the interpreter evaluates the elements of the combination and applies the
procedure (which is the value of the operator of the combination) to the
arguments (which are the values of the operands of the combination).

We can assume that the mechanism for applying primitive procedures to arguments
is built into the interpreter.  For compound procedures, the application
process is as follows:

\begin{quote}
To apply a compound procedure to arguments, evaluate the body of the procedure
with each formal parameter replaced by the corresponding argument.
\end{quote}

\noindent
To illustrate this process, let's evaluate the combination

\begin{scheme}
(f 5)
\end{scheme}

\noindent
where \code{f} is the procedure defined in \link{Section 1.1.4}.  We begin by
retrieving the body of \code{f}:

\begin{scheme}
(sum-of-squares (+ a 1) (* a 2))
\end{scheme}

\noindent
Then we replace the formal parameter \code{a} by the argument 5:

\begin{scheme}
(sum-of-squares (+ 5 1) (* 5 2))
\end{scheme}

\noindent
Thus the problem reduces to the evaluation of a combination with two operands
and an operator \code{sum\-/of\-/squares}.  Evaluating this combination involves
three subproblems.  We must evaluate the operator to get the procedure to be
applied, and we must evaluate the operands to get the arguments.  Now \code{(+
5 1)} produces 6 and \code{(* 5 2)} produces 10, so we must apply the
\code{sum\-/of\-/squares} procedure to 6 and 10.  These values are substituted for
the formal parameters \code{x} and \code{y} in the body of
\code{sum\-/of\-/squares}, reducing the expression to

\begin{scheme}
(+ (square 6) (square 10))
\end{scheme}

\noindent
If we use the definition of \code{square}, this reduces to

\begin{scheme}
(+ (* 6 6) (* 10 10))
\end{scheme}

\noindent
which reduces by multiplication to

\begin{scheme}
(+ 36 100)
\end{scheme}

\noindent
and finally to

\begin{scheme}
136
\end{scheme}

\noindent
The process we have just described is called the \newterm{substitution model}
for procedure application.  It can be taken as a model that determines the
``meaning'' of procedure application, insofar as the procedures in this chapter
are concerned.  However, there are two points that should be stressed:

\begin{itemize}

\item
The purpose of the substitution is to help us think about procedure
application, not to provide a description of how the interpreter really works.
Typical interpreters do not evaluate procedure applications by manipulating the
text of a procedure to substitute values for the formal parameters.  In
practice, the ``substitution'' is accomplished by using a local environment for
the formal parameters.  We will discuss this more fully in \link{Chapter 3} and
\link{Chapter 4} when we examine the implementation of an interpreter in detail.

\item
Over the course of this book, we will present a sequence of increasingly
elaborate models of how interpreters work, culminating with a complete
implementation of an interpreter and compiler in \link{Chapter 5}.  The
substitution model is only the first of these models---a way to get started
thinking formally about the evaluation process.  In general, when modeling
phenomena in science and engineering, we begin with simplified, incomplete
models.  As we examine things in greater detail, these simple models become
inadequate and must be replaced by more refined models.  The substitution model
is no exception.  In particular, when we address in \link{Chapter 3} the use of
procedures with ``mutable data,'' we will see that the substitution model
breaks down and must be replaced by a more complicated model of procedure
application.\footnote{Despite the simplicity of the substitution idea, it turns
out to be surprisingly complicated to give a rigorous mathematical definition
of the substitution process.  The problem arises from the possibility of
confusion between the names used for the formal parameters of a procedure and
the (possibly identical) names used in the expressions to which the procedure
may be applied.  Indeed, there is a long history of erroneous definitions of
\newterm{substitution} in the literature of logic and programming semantics.
See \link{Stoy 1977} for a careful discussion of substitution.}

\end{itemize}

\subsubsection*{Applicative order versus normal order}

According to the description of evaluation given in \link{Section 1.1.3}, the
interpreter first evaluates the operator and operands and then applies the
resulting procedure to the resulting arguments.  This is not the only way to
perform evaluation.  An alternative evaluation model would not evaluate the
operands until their values were needed.  Instead it would first substitute
operand expressions for parameters until it obtained an expression involving
only primitive operators, and would then perform the evaluation.  If we used
this method, the evaluation of \code{(f 5)} would proceed according to the
sequence of expansions

\begin{scheme}
(sum-of-squares (+ 5 1) (* 5 2))
(+   (square (+ 5 1))      (square (* 5 2))  )
(+   (* (+ 5 1) (+ 5 1))   (* (* 5 2) (* 5 2)))
\end{scheme}

\noindent
followed by the reductions

\begin{scheme}
(+      (* 6 6)      (* 10 10))
(+         36           100)
                136
\end{scheme}

\noindent
This gives the same answer as our previous evaluation model, but the process is
different.  In particular, the evaluations of \code{(+ 5 1)} and \code{(* 5 2)}
are each performed twice here, corresponding to the reduction of the expression
\code{(* x x)} with \code{x} replaced respectively by \code{(+ 5 1)} and
\code{(* 5 2)}.

This alternative ``fully expand and then reduce'' evaluation method is known as
\newterm{normal-order evaluation}, in contrast to the ``evaluate the arguments
and then apply'' method that the interpreter actually uses, which is called
\newterm{applicative-order evaluation}.  It can be shown that, for procedure
applications that can be modeled using substitution (including all the
procedures in the first two chapters of this book) and that yield legitimate
values, normal-order and applicative-order evaluation produce the same value.
(See \link{Exercise 1.5} for an instance of an ``illegitimate'' value where
normal-order and applicative-order evaluation do not give the same result.)

Lisp uses applicative-order evaluation, partly because of the additional
efficiency obtained from avoiding multiple evaluations of expressions such as
those illustrated with \code{(+ 5 1)} and \code{(* 5 2)} above and, more
significantly, because normal-order evaluation becomes much more complicated to
deal with when we leave the realm of procedures that can be modeled by
substitution.  On the other hand, normal-order evaluation can be an extremely
valuable tool, and we will investigate some of its implications in \link{Chapter
3} and \link{Chapter 4}.\footnote{In \link{Chapter 3} we will introduce
\newterm{stream processing}, which is a way of handling apparently ``infinite''
data structures by incorporating a limited form of normal-order evaluation.  In
\link{Section 4.2} we will modify the Scheme interpreter to produce a
normal-order variant of Scheme.}

\subsection{Conditional Expressions and Predicates}
\label{Section 1.1.6}

The expressive power of the class of procedures that we can define at this
point is very limited, because we have no way to make tests and to perform
different operations depending on the result of a test.  For instance, we
cannot define a procedure that computes the absolute value of a number by
testing whether the number is positive, negative, or zero and taking different
actions in the different cases according to the rule
\begin{comment}

\begin{example}
      /
      |   x  if x > 0
|x| = <   0  if x = 0
      |  -x  if x < 0
      \
\end{example}

\end{comment}

$$
 |x| = \left\{ \begin{array}{r@{\quad \mathrm{if} \quad}l}
        x  &  x > 0, \\
	0  &  x = 0, \\
  \!\! -x  &  x < 0. \end{array} \right.
$$

This construct is called a \newterm{case analysis}, and there is a special form
in Lisp for notating such a case analysis.  It is called \code{cond} (which
stands for ``conditional''), and it is used as follows:

\begin{scheme}
(define (abs x)
  (cond ((> x 0) x)
        ((= x 0) 0)
        ((< x 0) (- x))))
\end{scheme}

\noindent
The general form of a conditional expression is

\begin{scheme}
(cond (~\( \dark \langle \)~~\var{\dark p}~~\( \dark _{\mono{1}}\rangle \)~ ~\( \dark \langle \)~~\var{\dark e}~~\( \dark _{\mono{1}}\rangle \)~)
      (~\( \dark \langle \)~~\var{\dark p}~~\( \dark _{\mono{2}}\rangle \)~ ~\( \dark \langle \)~~\var{\dark e}~~\( \dark _{\mono{2}}\rangle \)~)
      ~\( \dots \)~
      (~\( \dark \langle \)~~\var{\dark p}~~\( \dark _{\monoit{n}}\rangle \)~ ~\( \dark \langle \)~~\var{\dark e}~~\( \dark _{\monoit{n}}\rangle \)~))
\end{scheme}

\noindent
consisting of the symbol \code{cond} followed by parenthesized pairs of
expressions

\begin{scheme}
(~\( \dark \langle \)~~\var{\dark p}~~\( \dark \rangle \)~ ~\( \dark \langle \)~~\var{\dark e}~~\( \dark \rangle \)~)
\end{scheme}

\noindent
called \newterm{clauses}. The first expression in each pair is a
\newterm{predicate}---that is, an expression whose value is interpreted as
either true or false.\footnote{``Interpreted as either true or false'' means
this: In Scheme, there are two distinguished values that are denoted by the
constants \code{\#t} and \code{\#f}.  When the interpreter checks a predicate's
value, it interprets \code{\#f} as false.  Any other value is treated as true.
(Thus, providing \code{\#t} is logically unnecessary, but it is convenient.)  In
this book we will use names \code{true} and \code{false}, which are associated
with the values \code{\#t} and \code{\#f} respectively.}

Conditional expressions are evaluated as follows.  The predicate \( \langle{p_1}\rangle \) is
evaluated first.  If its value is false, then \( \langle{p_2}\rangle \) is evaluated.  If
\( \langle{p_2}\rangle \)'s value is also false, then \( \langle{p_3}\rangle \) is evaluated.  This process
continues until a predicate is found whose value is true, in which case the
interpreter returns the value of the corresponding \newterm{consequent
expression} \( \langle{e}\rangle \) of the clause as the value of the conditional expression.
If none of the \( \langle{p}\rangle \)'s is found to be true, the value of the \code{cond} is
undefined.

The word \newterm{predicate} is used for procedures that return true or false,
as well as for expressions that evaluate to true or false.  The absolute-value
procedure \code{abs} makes use of the primitive predicates \code{>}, \code{<},
and \code{=}.\footnote{\code{abs} also uses the ``minus'' operator \code{-},
which, when used with a single operand, as in \code{(- x)}, indicates
negation.} These take two numbers as arguments and test whether the first
number is, respectively, greater than, less than, or equal to the second
number, returning true or false accordingly.

Another way to write the absolute-value procedure is

\begin{scheme}
(define (abs x)
  (cond ((< x 0) (- x))
        (else x)))
\end{scheme}

\noindent
which could be expressed in English as ``If \( x \) is less than zero return
\( -x; \) otherwise return \( x \).''  \code{else} is a special symbol that can be
used in place of the \( \langle{p}\rangle \) in the final clause of a \code{cond}.  This
causes the \code{cond} to return as its value the value of the corresponding
\( \langle{e}\rangle \) whenever all previous clauses have been bypassed.  In fact, any
expression that always evaluates to a true value could be used as the \( \langle{p}\rangle \)
here.

Here is yet another way to write the absolute-value procedure:

\begin{scheme}
(define (abs x)
  (if (< x 0)
      (- x)
      x))
\end{scheme}

\noindent
This uses the special form \code{if}, a restricted type of conditional that can
be used when there are precisely two cases in the case analysis.  The general
form of an \code{if} expression is

\begin{scheme}
(if ~\( \dark \langle\kern0.07em \)~~\var{\dark predicate}~~\( \dark \kern0.06em\rangle \)~ ~\( \dark \langle\kern0.07em \)~~\var{\dark consequent}~~\( \dark \kern0.05em\rangle \)~ ~\( \dark \langle\kern0.06em \)~~\var{\dark alternative}~~\( \dark \kern0.06em\rangle \)~)
\end{scheme}

\noindent
To evaluate an \code{if} expression, the interpreter starts by evaluating the
\( \langle \)\var{predicate}\( \kern0.04em\rangle \) part of the expression.  If the \( \langle \)\var{predicate}\( \kern0.04em\rangle \) evaluates
to a true value, the interpreter then evaluates the \( \langle \)\var{consequent}\( \kern0.04em\rangle \) and
returns its value.  Otherwise it evaluates the \( \langle \)\var{alternative}\( \kern0.04em\rangle \) and returns
its value.\footnote{A minor difference between \code{if} and \code{cond} is
that the \( \langle{e}\rangle \) part of each \code{cond} clause may be a sequence of
expressions.  If the corresponding \( \langle{p}\rangle \) is found to be true, the
expressions \( \langle{e}\rangle \) are evaluated in sequence and the value of the final
expression in the sequence is returned as the value of the \code{cond}.  In an
\code{if} expression, however, the \( \langle \)\var{consequent}\( \kern0.04em\rangle \) and \( \langle \)\var{alternative}\( \kern0.04em\rangle \)
must be single expressions.}

In addition to primitive predicates such as \code{<}, \code{=}, and \code{>},
there are logical composition operations, which enable us to construct compound
predicates.  The three most frequently used are these:

\begin{itemize}

\item
\( \hbox{\tt(and }\langle{e_1}\rangle\;\;\dots\;\;\langle{e_n}\rangle\hbox{\tt)} \)

The interpreter evaluates the expressions \( \langle{e}\kern0.08em\rangle \) one at a time, in
left-to-right order.  If any \( \langle{e}\kern0.08em\rangle \) evaluates to false, the value of the
\code{and} expression is false, and the rest of the \( \langle{e}\kern0.08em\rangle \)'s are not
evaluated.  If all \( \langle{e}\kern0.08em\rangle \)'s evaluate to true values, the value of the
\code{and} expression is the value of the last one.

\item
\( \hbox{\tt(or }\langle{e_1}\rangle\;\;\dots\;\;\langle{e_n}\rangle\hbox{\tt)} \)

The interpreter evaluates the expressions \( \langle{e}\kern0.08em\rangle \) one at a time, in
left-to-right order.  If any \( \langle{e}\kern0.08em\rangle \) evaluates to a true value, that value is
returned as the value of the \code{or} expression, and the rest of the
\( \langle{e}\kern0.08em\rangle \)'s are not evaluated.  If all \( \langle{e}\kern0.08em\rangle \)'s evaluate to false, the value
of the \code{or} expression is false.

\item
\( \hbox{\tt(not }\langle{e}\rangle\hbox{\tt)} \)

The value of a \code{not} expression is true when the expression \( \langle{e}\kern0.08em\rangle \)
evaluates to false, and false otherwise.

\end{itemize}

\noindent
Notice that \code{and} and \code{or} are special forms, not procedures, because
the subexpressions are not necessarily all evaluated.  \code{not} is an
ordinary procedure.

As an example of how these are used, the condition that a number \( x \) be in
the range \( 5 < x < 10 \) may be expressed as

\begin{scheme}
(and (> x 5) (< x 10))
\end{scheme}

\noindent
As another example, we can define a predicate to test whether one number is
greater than or equal to another as

\begin{scheme}
(define (>= x y) (or (> x y) (= x y)))
\end{scheme}

\noindent
or alternatively as

\begin{scheme}
(define (>= x y) (not (< x y)))
\end{scheme}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.1}Exercise 1.1:} Below is a sequence of expressions.
What is the result printed by the interpreter in response to each expression?
Assume that the sequence is to be evaluated in the order in which it is
presented.

\begin{scheme}
10
(+ 5 3 4)
(- 9 1)
(/ 6 2)
(+ (* 2 4) (- 4 6))
(define a 3)
(define b (+ a 1))
(+ a b (* a b))
(= a b)
(if (and (> b a) (< b (* a b)))
    b
    a)
\end{scheme}

\begin{scheme}
(cond ((= a 4) 6)
      ((= b 4) (+ 6 7 a))
      (else 25))
\end{scheme}

\begin{scheme}
(+ 2 (if (> b a) b a))
\end{scheme}

\begin{scheme}
(* (cond ((> a b) a)
         ((< a b) b)
         (else -1))
   (+ a 1))
\end{scheme}
\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.2}Exercise 1.2:} Translate the following expression
into prefix form:
\begin{comment}

\begin{example}
5 + 4 + (2 - (3 - (6 + 4/5)))
-----------------------------
       3(6 - 2)(2 - 7)
\end{example}

\end{comment}

$${5 + 4 + (2 - (3 - (6 + {4\over5})))\over3(6 - 2)(2 - 7)}.$$

\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.3}Exercise 1.3:} Define a procedure that takes three
numbers as arguments and returns the sum of the squares of the two larger
numbers.
\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.4}Exercise 1.4:} Observe that our model of
evaluation allows for combinations whose operators are compound expressions.
Use this observation to describe the behavior of the following procedure:

\begin{scheme}
(define (a-plus-abs-b a b)
  ((if (> b 0) + -) a b))
\end{scheme}
\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.5}Exercise 1.5:} Ben Bitdiddle has invented a test
to determine whether the interpreter he is faced with is using
applicative-order evaluation or normal-order evaluation.  He defines the
following two procedures:

\begin{scheme}
(define (p) (p))
(define (test x y)
  (if (= x 0) 0 y))
\end{scheme}

Then he evaluates the expression

\begin{scheme}
(test 0 (p))
\end{scheme}

What behavior will Ben observe with an interpreter that uses applicative-order
evaluation?  What behavior will he observe with an interpreter that uses
normal-order evaluation?  Explain your answer.  (Assume that the evaluation
rule for the special form \code{if} is the same whether the interpreter is
using normal or applicative order: The predicate expression is evaluated first,
and the result determines whether to evaluate the consequent or the alternative
expression.)
\end{quote}

\subsection{Example: Square Roots by Newton's Method}
\label{Section 1.1.7}

Procedures, as introduced above, are much like ordinary mathematical functions.
They specify a value that is determined by one or more parameters.  But there
is an important difference between mathematical functions and computer
procedures.  Procedures must be effective.

As a case in point, consider the problem of computing square roots.  We can
define the square-root function as
\begin{comment}

\begin{example}
sqrt(x) = the y such that y >= 0 and y^2 = x
\end{example}

\end{comment}

$$\sqrt{x}\;\; = {\rm\;\; the\;\;} y
{\rm\;\; such\;\; that\;\;} y \ge 0 {\rm\;\; and\;\;} y^2 = x.$$

This describes a perfectly legitimate mathematical function.  We could use it
to recognize whether one number is the square root of another, or to derive
facts about square roots in general.  On the other hand, the definition does
not describe a procedure.  Indeed, it tells us almost nothing about how to
actually find the square root of a given number.  It will not help matters to
rephrase this definition in pseudo-Lisp:

\begin{scheme}
(define (sqrt x)
  (the y (and (>= y 0)
              (= (square y) x))))
\end{scheme}

\noindent
This only begs the question.

The contrast between function and procedure is a reflection of the general
distinction between describing properties of things and describing how to do
things, or, as it is sometimes referred to, the distinction between declarative
knowledge and imperative knowledge.  In mathematics we are usually concerned
with declarative (what is) descriptions, whereas in computer science we are
usually concerned with imperative (how to) descriptions.\footnote{Declarative
and imperative descriptions are intimately related, as indeed are mathematics
and computer science.  For instance, to say that the answer produced by a
program is ``correct'' is to make a declarative statement about the program.
There is a large amount of research aimed at establishing techniques for
proving that programs are correct, and much of the technical difficulty of this
subject has to do with negotiating the transition between imperative statements
(from which programs are constructed) and declarative statements (which can be
used to deduce things).  In a related vein, an important current area in
programming-language design is the exploration of so-called very high-level
languages, in which one actually programs in terms of declarative statements.
The idea is to make interpreters sophisticated enough so that, given ``what
is'' knowledge specified by the programmer, they can generate ``how to''
knowledge automatically.  This cannot be done in general, but there are
important areas where progress has been made.  We shall revisit this idea in
\link{Chapter 4}.}

How does one compute square roots?  The most common way is to use Newton's
method of successive approximations, which says that whenever we have a guess
\( y \) for the value of the square root of a number \( x \), we can perform a
simple manipulation to get a better guess (one closer to the actual square
root) by averaging \( y \) with \( x / y \).\footnote{This square-root algorithm
is actually a special case of Newton's method, which is a general technique for
finding roots of equations.  The square-root algorithm itself was developed by
Heron of Alexandria in the first century \acronym{A.D.}  We will see how to
express the general Newton's method as a Lisp procedure in \link{Section 1.3.4}.}
For example, we can compute the square root of 2 as follows.
Suppose our initial guess is 1:

\vspace{-0.8em}
\begin{smallexample}
Guess       Quotient                 Average
1           (2/1) = 2                ((2 + 1)/2) = 1.5
1.5         (2/1.5) = 1.3333         ((1.3333 + 1.5)/2) = 1.4167
1.4167      (2/1.4167) = 1.4118      ((1.4167 + 1.4118)/2) = 1.4142
1.4142      ...                      ...
\end{smallexample}

\noindent
Continuing this process, we obtain better and better approximations to the
square root.

Now let's formalize the process in terms of procedures.  We start with a value
for the radicand (the number whose square root we are trying to compute) and a
value for the guess.  If the guess is good enough for our purposes, we are
done; if not, we must repeat the process with an improved guess.  We write this
basic strategy as a procedure:

\begin{scheme}
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
\end{scheme}

\noindent
A guess is improved by averaging it with the quotient of the radicand and the
old guess:

\begin{scheme}
(define (improve guess x)
  (average guess (/ x guess)))
\end{scheme}

\noindent
where

\begin{scheme}
(define (average x y)
  (/ (+ x y) 2))
\end{scheme}

\noindent
We also have to say what we mean by ``good enough.''  The following will do for
illustration, but it is not really a very good test.  (See \link{Exercise 1.7}.)
The idea is to improve the answer until it is close
enough so that its square differs from the radicand by less than a
predetermined tolerance (here 0.001):\footnote{We will usually give predicates
names ending with question marks, to help us remember that they are predicates.
This is just a stylistic convention.  As far as the interpreter is concerned,
the question mark is just an ordinary character.}

\begin{scheme}
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
\end{scheme}

\noindent
Finally, we need a way to get started.  For instance, we can always guess that
the square root of any number is 1:\footnote{Observe that we express our
initial guess as 1.0 rather than 1.  This would not make any difference in many
Lisp implementations.  \acronym{MIT} Scheme, however, distinguishes between
exact integers and decimal values, and dividing two integers produces a
rational number rather than a decimal.  For example, dividing 10 by 6 yields
5/3, while dividing 10.0 by 6.0 yields 1.6666666666666667.  (We will learn how
to implement arithmetic on rational numbers in \link{Section 2.1.1}.)  If we
start with an initial guess of 1 in our square-root program, and \( x \) is an
exact integer, all subsequent values produced in the square-root computation
will be rational numbers rather than decimals.  Mixed operations on rational
numbers and decimals always yield decimals, so starting with an initial guess
of 1.0 forces all subsequent values to be decimals.}

\begin{scheme}
(define (sqrt x)
  (sqrt-iter 1.0 x))
\end{scheme}

\noindent
If we type these definitions to the interpreter, we can use \code{sqrt} just as
we can use any procedure:

\begin{scheme}
(sqrt 9)
~\textit{3.00009155413138}~

(sqrt (+ 100 37))
~\textit{11.704699917758145}~

(sqrt (+ (sqrt 2) (sqrt 3)))
~\textit{1.7739279023207892}~

(square (sqrt 1000))
~\textit{1000.000369924366}~
\end{scheme}

\noindent
The \code{sqrt} program also illustrates that the simple procedural language we
have introduced so far is sufficient for writing any purely numerical program
that one could write in, say, C or Pascal.  This might seem surprising, since
we have not included in our language any iterative (looping) constructs that
direct the computer to do something over and over again.  \code{sqrt\-/iter}, on
the other hand, demonstrates how iteration can be accomplished using no special
construct other than the ordinary ability to call a procedure.\footnote{Readers
who are worried about the efficiency issues involved in using procedure calls
to implement iteration should note the remarks on ``tail recursion'' in
\link{Section 1.2.1}.}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.6}Exercise 1.6:} Alyssa P. Hacker doesn't see why
\code{if} needs to be provided as a special form.  ``Why can't I just define it
as an ordinary procedure in terms of \code{cond}?'' she asks.  Alyssa's friend
Eva Lu Ator claims this can indeed be done, and she defines a new version of
\code{if}:

\begin{scheme}
(define (new-if predicate then-clause else-clause)
  (cond (predicate then-clause)
        (else else-clause)))
\end{scheme}

Eva demonstrates the program for Alyssa:

\begin{scheme}
(new-if (= 2 3) 0 5)
~\textit{5}~
(new-if (= 1 1) 0 5)
~\textit{0}~
\end{scheme}

Delighted, Alyssa uses \code{new\-/if} to rewrite the square-root program:

\begin{scheme}
(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x) x)))
\end{scheme}

What happens when Alyssa attempts to use this to compute square roots?
Explain.
\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.7}Exercise 1.7:} The \code{good\-/enough?} test used
in computing square roots will not be very effective for finding the square
roots of very small numbers.  Also, in real computers, arithmetic operations
are almost always performed with limited precision.  This makes our test
inadequate for very large numbers.  Explain these statements, with examples
showing how the test fails for small and large numbers.  An alternative
strategy for implementing \code{good\-/enough?} is to watch how \code{guess}
changes from one iteration to the next and to stop when the change is a very
small fraction of the guess.  Design a square-root procedure that uses this
kind of end test.  Does this work better for small and large numbers?
\end{quote}

\begin{quote}
\heading{\phantomsection\label{Exercise 1.8}Exercise 1.8:} Newton's method for cube roots is
based on the fact that if \( y \) is an approximation to the cube root of \( x \),
then a better approximation is given by the value
\begin{comment}

\begin{example}
x/y^2 + 2y
----------
    3
\end{example}

\end{comment}

$${{x / y^2} + 2y \over 3}.$$

\noindent
Use this formula to implement a cube-root procedure analogous to the
square-root procedure.  (In \link{Section 1.3.4} we will see how to implement
Newton's method in general as an abstraction of these square-root and cube-root
procedures.)
\end{quote}

\subsection{Procedures as Black-Box Abstractions}
\label{Section 1.1.8}

\code{sqrt} is our first example of a process defined by a set of mutually
defined procedures.  Notice that the definition of \code{sqrt\-/iter} is
\newterm{recursive}; that is, the procedure is defined in terms of itself.  The
idea of being able to define a procedure in terms of itself may be disturbing;
it may seem unclear how such a ``circular'' definition could make sense at all,
much less specify a well-defined process to be carried out by a computer.  This
will be addressed more carefully in \link{Section 1.2}.  But first let's
consider some other important points illustrated by the \code{sqrt} example.

Observe that the problem of computing square roots breaks up naturally into a
number of subproblems: how to tell whether a guess is good enough, how to
improve a guess, and so on.  Each of these tasks is accomplished by a separate
procedure.  The entire \code{sqrt} program can be viewed as a cluster of
procedures (shown in \link{Figure 1.2}) that mirrors the decomposition of the
problem into subproblems.

\begin{figure}[tb]
\phantomsection\label{Figure 1.2}
\centering
\begin{comment}
\heading{Figure 1.2:} Procedural decomposition of the \code{sqrt} program.

\begin{example}
                       sqrt
                        |
                    sqrt-iter
                    /       \
            good-enough    improve
              /     \          \
          square    abs      average
\end{example}
\end{comment}
\includesvg[width=44mm]{fig/chap1/Fig1.2.svg}
\begin{quote}
\heading{Figure 1.2:} Procedural decomposition of the \code{sqrt} program.
\end{quote}
\end{figure}

The importance of this decomposition strategy is not simply that one is
dividing the program into parts.  After all, we could take any large program
and divide it into parts---the first ten lines, the next ten lines, the next
ten lines, and so on.  Rather, it is crucial that each procedure accomplishes
an identifiable task that can be used as a module in defining other procedures.
For example, when we define the \code{good\-/enough?} procedure in terms of
\code{square}, we are able to regard the \code{square} procedure as a ``black
box.''  We are not at that moment concerned with \emph{how} the procedure
computes its result, only with the fact that it computes the square.  The
details of how the square is computed can be suppressed, to be considered at a
later time.  Indeed, as far as the \code{good\-/enough?} procedure is concerned,
\code{square} is not quite a procedure but rather an abstraction of a
procedure, a so-called \newterm{procedural abstraction}.  At this level of
abstraction, any procedure that computes the square is equally good.

Thus, considering only the values they return, the following two procedures for
squaring a number should be indistinguishable.  Each takes a numerical argument
and produces the square of that number as the value.\footnote{It is not even
clear which of these procedures is a more efficient implementation.  This
depends upon the hardware available.  There are machines for which the
``obvious'' implementation is the less efficient one.  Consider a machine that
has extensive tables of logarithms and antilogarithms stored in a very
efficient manner.}

\begin{scheme}
(define (square x) (* x x))
(define (square x) (exp (double (log x))))
(define (double x) (+ x x))
\end{scheme}

\noindent
So a procedure definition should be able to suppress detail.  The users of the
procedure may not have written the procedure themselves, but may have obtained
it from another programmer as a black box.  A user should not need to know how
the procedure is implemented in order to use it.

\subsubsection*{Local names}

One detail of a procedure's implementation that should not matter to the user
of the procedure is the implementer's choice of names for the procedure's
formal parameters.  Thus, the following procedures should not be
distinguishable:

\begin{scheme}
(define (square x) (* x x))
(define (square y) (* y y))
\end{scheme}

\noindent
This principle---that the meaning of a procedure should be independent of the
parameter names used by its author---seems on the surface to be self-evident,
but its consequences are profound.  The simplest consequence is that the
parameter names of a procedure must be local to the body of the procedure.  For
example, we used \code{square} in the definition of \code{good\-/enough?} in our
square-root procedure:

\begin{scheme}
(define (good-enough? guess x)
  (< (abs (- (square guess) x))
     0.001))
\end{scheme}

\noindent
The intention of the author of \code{good\-/enough?} is to determine if the
square of the first argument is within a given tolerance of the second
argument.  We see that the author of \code{good\-/enough?} used the name
\code{guess} to refer to the first argument and \code{x} to refer to the second
argument.  The argument of \code{square} is \code{guess}.  If the author of
\code{square} used \code{x} (as above) to refer to that argument, we see that
the \code{x} in \code{good\-/enough?} must be a different \code{x} than the one
in \code{square}.  Running the procedure \code{square} must not affect the
value of \code{x} that is used by \code{good\-/enough?}, because that value of
\code{x} may be needed by \code{good\-/enough?} after \code{square} is done
computing.

If the parameters were not local to the bodies of their respective procedures,
then the parameter \code{x} in \code{square} could be confused with the
parameter \code{x} in \code{good\-/enough?}, and the behavior of
\code{good\-/enough?} would depend upon which version of \code{square} we used.
Thus, \code{square} would not be the black box we desired.

A formal parameter of a procedure has a very special role in the procedure
definition, in that it doesn't matter what name the formal parameter has.  Such
a name is called a \newterm{bound variable}, and we say that the procedure
definition \newterm{binds} its formal parameters.  The meaning of a procedure
definition is unchanged if a bound variable is consistently renamed throughout
the definition.\footnote{The concept of consistent renaming is actually subtle
and difficult to define formally.  Famous logicians have made embarrassing
errors here.}  If a variable is not bound, we say that it is \newterm{free}.
The set of expressions for which a binding defines a name is called the
\newterm{scope} of that name.  In a procedure definition, the bound variables
declared as the formal parameters of the procedure have the body of the
procedure as their scope.

In the definition of \code{good\-/enough?} above, \code{guess} and \code{x} are
bound variables but \code{<}, \code{-}, \code{abs}, and \code{square} are free.
The meaning of \code{good\-/enough?} should be independent of the names we choose
for \code{guess} and \code{x} so long as they are distinct and different from
\code{<}, \code{-}, \code{abs}, and \code{square}.  (If we renamed \code{guess}
to \code{abs} we would have introduced a bug by \newterm{capturing} the
variable \code{abs}.  It would have changed from free to bound.)  The meaning
of \code{good\-/enough?} is not independent of the names of its free variables,
however.  It surely depends upon the fact (external to this definition) that
the symbol \code{abs} names a procedure for computing the absolute value of a
number.  \code{good\-/enough?} will compute a different function if we substitute
\code{cos} for \code{abs} in its definition.

\subsubsection*{Internal definitions and block structure}

We have one kind of name isolation available to us so far: The formal
parameters of a procedure are local to the body of the procedure.  The
square-root program illustrates another way in which we would like to control
the use of names.  The existing program consists of separate procedures:

\begin{scheme}
(define (sqrt x)
  (sqrt-iter 1.0 x))
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
(define (improve guess x)
  (average guess (/ x guess)))
\end{scheme}

\noindent
The problem with this program is that the only procedure that is important to
users of \code{sqrt} is \code{sqrt}.  The other procedures (\code{sqrt\-/iter},
\code{good\-/enough?}, and \code{improve}) only clutter up their minds.  They may
not define any other procedure called \code{good\-/enough?} as part of another
program to work together with the square-root program, because \code{sqrt}
needs it.  The problem is especially severe in the construction of large
systems by many separate programmers.  For example, in the construction of a
large library of numerical procedures, many numerical functions are computed as
successive approximations and thus might have procedures named
\code{good\-/enough?} and \code{improve} as auxiliary procedures.  We would like
to localize the subprocedures, hiding them inside \code{sqrt} so that
\code{sqrt} could coexist with other successive approximations, each having its
own private \code{good\-/enough?} procedure.  To make this possible, we allow a
procedure to have internal definitions that are local to that procedure.  For
example, in the square-root problem we can write

\begin{scheme}
(define (sqrt x)
  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess x) (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))
\end{scheme}

\noindent
Such nesting of definitions, called \newterm{block structure}, is basically the
right solution to the simplest name-packaging problem.  But there is a better
idea lurking here.  In addition to internalizing the definitions of the
auxiliary procedures, we can simplify them.  Since \code{x} is bound in the
definition of \code{sqrt}, the procedures \code{good\-/enough?}, \code{improve},
and \code{sqrt\-/iter}, which are defined internally to \code{sqrt}, are in the
scope of \code{x}.  Thus, it is not necessary to pass \code{x} explicitly to
each of these procedures.  Instead, we allow \code{x} to be a free variable in
the internal definitions, as shown below. Then \code{x} gets its value from the
argument with which the enclosing procedure \code{sqrt} is called.  This
discipline is called \newterm{lexical scoping}.\footnote{Lexical scoping dictates
that free variables in a procedure are taken to refer to bindings made by enclosing
procedure definitions; that is, they are looked up in the environment in which the
procedure was defined. We will see how this works in detail in chapter 3 when we study
environments and the detailed behavior of the interpreter.\label{Footnote 28}}

\begin{scheme}
(define (sqrt x)
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
\end{scheme}

\enlargethispage{\baselineskip}

\noindent
We will use block structure extensively to help us break up large
programs into tractable pieces.\footnote{Embedded definitions must come
first in a procedure body. The management is not responsible for the
consequences of running programs that intertwine definition and use.}
The idea of block structure originated with the programming language
Algol 60. It appears in most advanced programming languages and is an
important tool for helping to organize the construction of large
programs.
