\subsection{Structure of the Compiler}
\label{Section 5.5.1}

In \cref{Section 4.1.7} we modified our original metacircular interpreter to separate analysis from execution.
We analyzed each expression to produce an execution procedure that took an environment as argument and performed the required operations.
In our compiler, we will do essentially the same analysis.
Instead of producing execution procedures, however, we will generate sequences of instructions to be run by our register machine.

The procedure \code{compile} is the top-level dispatch in the compiler.
It corresponds to the \code{eval} procedure of \cref{Section 4.1.1}, the \code{analyze} procedure of \cref{Section 4.1.7}, and the \code{eval-dispatch} entry point of the explicit-control-evaluator in \cref{Section 5.4.1}.
The compiler, like the interpreters, uses the expression-syntax procedures defined in \cref{Section 4.1.2}.%
\footnote{
	Notice, however, that our compiler is a Scheme program, and the syntax procedures that it uses to manipulate expressions are the actual Scheme procedures used with the metacircular evaluator.
	For the explicit-control evaluator, in contrast, we assumed that equivalent syntax operations were available as operations for the register machine.
	(Of course, when we simulated the register machine in Scheme, we used the actual Scheme procedures in our register machine simulation.)
}
\code{compile} performs a case analysis on the syntactic type of the expression to be compiled.
For each type of expression, it dispatches to a specialized \newterm{code generator}:
\begin{scheme}
  (define (compile exp target linkage)
    (cond ((self-evaluating? exp)
           (compile-self-evaluating exp target linkage))
          ((quoted? exp) (compile-quoted exp target linkage))
          ((variable? exp)
           (compile-variable exp target linkage))
          ((assignment? exp)
           (compile-assignment exp target linkage))
          ((definition? exp)
           (compile-definition exp target linkage))
          ((if? exp) (compile-if exp target linkage))
          ((lambda? exp) (compile-lambda exp target linkage))
          ((begin? exp)
           (compile-sequence
            (begin-actions exp) target linkage))
          ((cond? exp)
           (compile (cond->if exp) target linkage))
          ((application? exp)
           (compile-application exp target linkage))
          (else
           (error "Unknown expression type: COMPILE" exp))))
\end{scheme}



\subsubsection*{Targets and linkages}

\code{compile} and the code generators that it calls take two arguments in addition to the expression to compile.
There is a \newterm{target}, which specifies the register in which the compiled code is to return the value of the expression.
There is also a \newterm{linkage descriptor}, which describes how the code resulting from the compilation of the expression should proceed when it has finished its execution.
The linkage descriptor can require that the code do one of the following three things:
\begin{itemize}

	\item
		continue at the next instruction in sequence (this is specified by the linkage descriptor \code{next}),

	\item
		return from the procedure being compiled (this is specified by the linkage descriptor \code{return}), or

	\item
		jump to a named entry point (this is specified by using the designated label as the linkage descriptor).

\end{itemize}

For example, compiling the expression \code{5} (which is self-evaluating) with
a target of the \code{val} register and a linkage of \code{next} should produce
the instruction
\begin{scheme}
  (assign val (const 5))
\end{scheme}
Compiling the same expression with a linkage of \code{return} should produce the instructions
\begin{scheme}
  (assign val (const 5))
  (goto (reg continue))
\end{scheme}
In the first case, execution will continue with the next instruction in the sequence.
In the second case, we will return from a procedure call.
In both cases, the value of the expression will be placed into the target \code{val} register.



\subsubsection*{Instruction sequences and stack usage}

Each code generator returns an \newterm{instruction sequence} containing the object code it has generated for the expression.
Code generation for a compound expression is accomplished by combining the output from simpler code generators for component expressions, just as evaluation of a compound expression is accomplished by evaluating the component expressions.

The simplest method for combining instruction sequences is a procedure called \code{append-instruction-sequences}.
It takes as arguments any number of instruction sequences that are to be executed sequentially;
it appends them and returns the combined sequence.
That is, if \code{⟨\var{seq}\ind{1}⟩} and \code{⟨\var{seq}\ind{2}⟩} are sequences of instructions, then evaluating
\begin{scheme}
  (append-instruction-sequences ⟨~\var{seq}\ind{1}~⟩ ⟨~\var{seq}\ind{2}~⟩)
\end{scheme}
produces the sequence
\begin{scheme}
  ⟨~\var{seq}\ind{1}~⟩
  ⟨~\var{seq}\ind{2}~⟩
\end{scheme}

Whenever registers might need to be saved, the compiler’s code generators use \code{preserving}, which is a more subtle method for combining instruction sequences.
\code{preserving} takes three arguments:
a set of registers and two instruction sequences that are to be executed sequentially.
It appends the sequences in such a way that the contents of each register in the set is preserved over the execution of the first sequence, if this is needed for the execution of the second sequence.
That is, if the first sequence modifies the register and the second sequence actually needs the register’s original contents, then \code{preserving} wraps a \code{save} and a \code{restore} of the register around the first sequence before appending the sequences.
Otherwise, \code{preserving} simply returns the appended instruction sequences.
Thus, for example,
\begin{scheme}
  (preserving (list ⟨~\var{reg}\ind{1}~⟩ ⟨~\var{reg}\ind{2}~⟩) ⟨~\var{seq}\ind{1}~⟩ ⟨~\var{seq}\ind{2}~⟩)
\end{scheme}
produces one of the following four sequences of instructions, depending on how \code{⟨\var{seq}\ind{1}⟩} and \code{⟨\var{seq}\ind{2}⟩} use \code{⟨\var{reg}\ind{1}⟩} and \code{⟨\var{reg}\ind{2}⟩}:
\begin{center}
	\begin{tabular}{l|l|l|l}
		\code{⟨\var{seq}\ind{1}⟩}
		&
		\code{(save ⟨\var{reg}\ind{1}⟩)}
		&
		\code{(save ⟨\var{reg}\ind{2}⟩)}
		&
		\code{(save ⟨\var{reg}\ind{2}⟩)}
		\\
		\code{⟨\var{seq}\ind{2}⟩}
		&
		\code{⟨\var{seq}\ind{1}⟩}
		&
		\code{⟨\var{seq}\ind{1}⟩}
		&
		\code{(save ⟨\var{reg}\ind{1}⟩)}
		\\
		{}
		&
		\code{(restore ⟨\var{reg}\ind{1}⟩)}
		&
		\code{(restore ⟨\var{reg}\ind{2}⟩)}
		&
		\code{⟨\var{seq}\ind{1}⟩}
		\\
		{}
		&
		\code{⟨\var{seq}\ind{2}⟩}
		&
		\code{⟨\var{seq}\ind{2}⟩}
		&
		\code{(restore ⟨\var{reg}\ind{1}⟩)}
		\\
		{}
		&
		{}
		&
		{}
		&
		\code{(restore ⟨\var{reg}\ind{2}⟩)}
		\\
		{}
		&
		{}
		&
		{}
		&
		\code{⟨\var{seq}\ind{2}⟩}
	\end{tabular}
\end{center}

By using \code{preserving} to combine instruction sequences the compiler avoids unnecessary stack operations.
This also isolates the details of whether or not to generate \code{save} and \code{restore} instructions within the \code{preserving} procedure, separating them from the concerns that arise in writing each of the individual code generators.
In fact no \code{save} or \code{restore} instructions are explicitly produced by the code generators.

In principle, we could represent an instruction sequence simply as a list of instructions.
\code{append-instruction-sequences} could then combine instruction sequences by performing an ordinary list \code{append}.
However, \code{preserving} would then be a complex operation, because it would have to analyze each instruction sequence to determine how the sequence uses its registers.
\code{preserving} would be inefficient as well as complex, because it would have to analyze each of its instruction sequence arguments, even though these sequences might themselves have been constructed by calls to \code{preserving}, in which case their parts would have already been analyzed.
To avoid such repetitious analysis we will associate with each instruction sequence some information about its register use.
When we construct a basic instruction sequence we will provide this information explicitly, and the procedures that combine instruction sequences will derive register-use information for the combined sequence from the information associated with the component sequences.

An instruction sequence will contain three pieces of information:
\begin{itemize}

	\item
		the set of registers that must be initialized before the instructions in the sequence are executed (these registers are said to be \newterm{needed} by the sequence),

	\item
		the set of registers whose values are modified by the instructions in the sequence, and

	\item
		the actual instructions (also called \newterm{statements}) in the sequence.

\end{itemize}
We will represent an instruction sequence as a list of its three parts.
The constructor for instruction sequences is thus
\begin{scheme}
  (define (make-instruction-sequence
           needs modifies statements)
    (list needs modifies statements))
\end{scheme}

For example, the two-instruction sequence that looks up the value of the variable \code{x} in the current environment, assigns the result to \code{val}, and then returns, requires registers \code{env} and \code{continue} to have been initialized, and modifies register \code{val}.
This sequence would therefore be constructed as
\begin{scheme}
  (make-instruction-sequence
   '(env continue)
   '(val)
   '((assign val
             (op lookup-variable-value) (const x) (reg env))
     (goto (reg continue))))
\end{scheme}

We sometimes need to construct an instruction sequence with no statements:
\begin{scheme}
  (define (empty-instruction-sequence)
    (make-instruction-sequence '() '() '()))
\end{scheme}
The procedures for combining instruction sequences are shown in \cref{Section 5.5.4}.



\begin{exercise}
	\label{Exercise 5.31}
	In evaluating a procedure application, the explicit-control evaluator always saves and restores the \code{env} register around the evaluation of the operator, saves and restores \code{env} around the evaluation of each operand (except the final one), saves and restores \code{argl} around the evaluation of each operand, and saves and restores \code{proc} around the evaluation of the operand sequence.
	For each of the following combinations, say which of these \code{save} and \code{restore} operations are superfluous and thus could be eliminated by the compiler’s \code{preserving} mechanism:
	\begin{scheme}
	  (f 'x 'y)
	  ((f) 'x 'y)
	  (f (g 'x) y)
	  (f (g 'x) 'y)
	\end{scheme}
\end{exercise}



\begin{exercise}
	\label{Exercise 5.32}
	Using the \code{preserving} mechanism, the compiler will avoid saving and restoring \code{env} around the evaluation of the operator of a combination in the case where the operator is a symbol.
	We could also build such optimizations into the evaluator.
	Indeed, the explicit-control evaluator of \cref{Section 5.4} already performs a similar optimization, by treating combinations with no operands as a special case.
	\begin{enumerate}[label = \alph*., leftmargin = *]

		\item
			Extend the explicit-control evaluator to recognize as a separate class of expressions combinations whose operator is a symbol, and to take advantage of this fact in evaluating such expressions.

		\item
			Alyssa P. Hacker suggests that by extending the evaluator to recognize more and more special cases we could incorporate all the compiler’s optimizations, and that this would eliminate the advantage of compilation altogether.
			What do you think of this idea?

	\end{enumerate}
\end{exercise}
