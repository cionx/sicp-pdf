\subsection{Lexical Addressing}
\label{Section 5.5.6}

One of the most common optimizations performed by compilers is the optimization of variable lookup.
Our compiler, as we have implemented it so far, generates code that uses the \code{lookup-variable-value} operation of the evaluator machine.
This searches for a variable by comparing it with each variable that is currently bound, working frame by frame outward through the run-time environment.
This search can be expensive if the frames are deeply nested or if there are many variables.
For example, consider the problem of looking up the value of \code{x} while evaluating the expression \code{(* x y z)} in an application of the procedure that is returned by
\begin{scheme}
  (let ((x 3) (y 4))
    (lambda (a b c d e)
      (let ((y (* a b x)) (z (+ c d x)))
        (* x y z))))
\end{scheme}
Since a \code{let} expression is just syntactic sugar for a \code{lambda} combination, this expression is equivalent to
\begin{scheme}
  ((lambda (x y)
     (lambda (a b c d e)
       ((lambda (y z) (* x y z))
        (* a b x)
        (+ c d x))))
   3
   4)
\end{scheme}
Each time \code{lookup-variable-value} searches for \code{x}, it must determine that the symbol \code{x} is not \code{eq?} to \code{y} or \code{z} (in the first frame), nor to \code{a}, \code{b}, \code{c}, \code{d}, or \code{e} (in the second frame).
We will assume, for the moment, that our programs do not use \code{define}---that variables are bound only with \code{lambda}.
Because our language is lexically scoped, the run-time environment for any expression will have a structure that parallels the lexical structure of the program in which the expression appears.%
\footnote{
	This is not true if we allow internal definitions, unless we scan them out.
	See \cref{Exercise 5.43}.
}
Thus, the compiler can know, when it analyzes the above expression, that each time the procedure is applied the variable \code{x} in \code{(* x y z)} will be found two frames out from the current frame and will be the first variable in that frame.

We can exploit this fact by inventing a new kind of variable-lookup operation, \code{lexical-address-lookup}, that takes as arguments an environment and a \newterm{lexical address} that consists of two numbers:
a \newterm{frame number}, which specifies how many frames to pass over, and a \newterm{displacement number}, which specifies how many variables to pass over in that frame.
\code{lexical-address-lookup} will produce the value of the variable stored at that lexical address relative to the current environment.
If we add the \code{lexical-address-lookup} operation to our machine, we can make the compiler generate code that references variables using this operation, rather than \code{lookup-variable-value}.
Similarly, our compiled code can use a new \code{lexical-address-set!}  operation instead of \code{set-variable-value!}.

In order to generate such code, the compiler must be able to determine the lexical address of a variable it is about to compile a reference to.
The lexical address of a variable in a program depends on where one is in the code.
For example, in the following program, the address of \code{x} in expression \code{⟨\var{e1}⟩} is (2, 0)---two frames back and the first variable in the frame.
At that point \code{y} is at address (0, 0) and \code{c} is at address (1, 2).
In expression ⟨\var{e2}, \code{x} is at (1, 0), \code{y} is at (1, 1), and \code{c} is at (0, 2).

\begin{scheme}
  ((lambda (x y)
     (lambda (a b c d e)
       ((lambda (y z) ⟨~\var{\dark e1}~⟩)
        ⟨~\var{\dark e2}~⟩
        (+ c d x))))
   3
 4)
\end{scheme}

One way for the compiler to produce code that uses lexical addressing is to maintain a data structure called a \newterm{compile-time environment}.
This keeps track of which variables will be at which positions in which frames in the run-time environment when a particular variable-access operation is executed.
The compile-time environment is a list of frames, each containing a list of variables.
(There will of course be no values bound to the variables, since values are not computed at compile time.)
The compile-time environment becomes an additional argument to \code{compile} and is passed along to each code generator.
The top-level call to \code{compile} uses an empty compile-time environment.
When a \code{lambda} body is compiled, \code{compile-lambda-body} extends the compile-time environment by a frame containing the procedure’s parameters, so that the sequence making up the body is compiled with that extended environment.
At each point in the compilation, \code{compile-variable} and \code{compile-assignment} use the compile-time environment in order to generate the appropriate lexical addresses.

\cref{Exercise 5.39} through \cref{Exercise 5.43} describe how to complete this sketch of the lexical-addressing strategy in order to incorporate lexical lookup into the compiler.
\cref{Exercise 5.44} describes another use for the compile-time environment.



\begin{exercise}
	\label{Exercise 5.39}
	Write a procedure \code{lexical-address-lookup} that implements the new lookup operation.
	It should take two arguments---a lexical address and a run-time environment---and return the value of the variable stored at the specified lexical address.
	\code{lexical-address-lookup} should signal an error if the value of the variable is the symbol \code{*unassigned*}.%
	\footnote{
		This is the modification to variable lookup required if we implement the scanning method to eliminate internal definitions (\cref{Exercise 5.43}).
		We will need to eliminate these definitions in order for lexical addressing to work.
	}
	Also write a procedure \code{lexical-address-set!} that implements the operation that changes the value of the variable at a specified lexical address.
\end{exercise}



\begin{exercise}
	\label{Exercise 5.40}
	Modify the compiler to maintain the compile-time environment as described above.
	That is, add a compile-time-environment argument to \code{compile} and the various code generators, and extend it in \code{compile-lambda-body}.
\end{exercise}



\begin{exercise}
	\label{Exercise 5.41}
	Write a procedure \code{find-variable} that takes as arguments a variable and a compile-time environment and returns the lexical address of the variable with respect to that environment.
	For example, in the program fragment that is shown above, the compile-time environment during the compilation of expression \code{⟨\var{e1}⟩} is \code{((y z) (a b c d e) (x y))}.
	\code{find-variable} should produce

	\begin{scheme}
	  (find-variable 'c '((y z) (a b c d e) (x y)))
	  ~\outprint{(1 2)}~

	  (find-variable 'x '((y z) (a b c d e) (x y)))
	  ~\outprint{(2 0)}~

	  (find-variable 'w '((y z) (a b c d e) (x y)))
	  ~\outprint{not-found}~
	\end{scheme}
\end{exercise}



\begin{exercise}
	\label{Exercise 5.42}
	Using \code{find-variable} from \cref{Exercise 5.41}, rewrite \code{compile-variable} and \code{compile-assignment} to output lexical-address instructions.
	In cases where \code{find-variable} returns \code{not-found} (that is, where the variable is not in the compile-time environment), you should have the code generators use the evaluator operations, as before, to search for the binding.
	(The only place a variable that is not found at compile time can be is in the global environment, which is part of the run-time environment but is not part of the compile-time environment.%
	\footnote{
		Lexical addresses cannot be used to access variables in the global environment, because these names can be defined and redefined interactively at any time.
		With internal definitions scanned out, as in \cref{Exercise 5.43}, the only definitions the compiler sees are those at top level, which act on the global environment.
		Compilation of a definition does not cause the defined name to be entered in the compile-time environment.
	}
	Thus, if you wish, you may have the evaluator operations look directly in the global environment, which can be obtained with the operation \code{(op get-global-environment)}, instead of having them search the whole run-time environment found in \code{env}.)
	Test the modified compiler on a few simple cases, such as the nested \code{lambda} combination at the beginning of this section.
\end{exercise}



\begin{exercise}
	\label{Exercise 5.43}
	We argued in \cref{Section 4.1.6} that internal definitions for block structure should not be considered “real” \code{define}s.
	Rather, a procedure body should be interpreted as if the internal variables being defined were installed as ordinary \code{lambda} variables initialized to their correct values using \code{set!}.
	\cref{Section 4.1.6} and \cref{Exercise 4.16} showed how to modify the metacircular interpreter to accomplish this by scanning out internal definitions.
	Modify the compiler to perform the same transformation before it compiles a procedure body.
\end{exercise}



\begin{exercise}
	\label{Exercise 5.44}
	In this section we have focused on the use of the compile-time environment to produce lexical addresses.
	But there are other uses for compile-time environments.
	For instance, in \cref{Exercise 5.38} we increased the efficiency of compiled code by open-coding primitive procedures.
	Our implementation treated the names of open-coded procedures as reserved words.
	If a program were to rebind such a name, the mechanism described in \cref{Exercise 5.38} would still open-code it as a primitive, ignoring the new binding.
	For example, consider the procedure
	\begin{scheme}
	  (lambda (+ * a b x y)
	    (+ (* a x) (* b y)))
	\end{scheme}
	which computes a linear combination of \code{x} and \code{y}.
	We might call it with arguments \code{+matrix}, \code{*matrix}, and four matrices, but the open-coding compiler would still open-code the \code{+} and the \code{*} in \code{(+ (* a x) (* b y))} as primitive \code{+} and \code{*}.
	Modify the open-coding compiler to consult the compile-time environment in order to compile the correct code for expressions involving the names of primitive procedures.
	(The code will work correctly as long as the program does not \code{define} or \code{set!} these names.)
\end{exercise}
